{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c48ce335",
   "metadata": {},
   "source": [
    "# Project Part 2\n",
    "\n",
    "FYI: The code in JNotebook doesn't seem to want to run, but no errors are presented. To view the outputs, open in colab/kaggle.\n",
    "\n",
    "[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://colab.research.google.com/github/PGLavergne/NYTCrosswordPredicter/blob/main/Part%20II/Project_Part_II.ipynb)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PGLavergne/NYTCrosswordPredicter/blob/main/Part%20II/Project_Part_II.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02c0fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/PGLavergne/NYTCrosswordPredicter/main/nytcrosswords.csv'\n",
    "dataSet = pd.read_csv(url, encoding='latin-1')\n",
    "dataSet_partial = pd.read_csv(url, encoding='latin-1', nrows=10000)\n",
    "dataSet_partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4425c86d",
   "metadata": {},
   "source": [
    "The code below creates histograms that represent the distribution of clue lengths in terms of words and the distribution of answer lengths in terms of characters. As you can see, most of the clue lengths are below 5 words and the length of the answer is usually less than 5 characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd309aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code calculates the clue/answer lengths in terms of words/chars, respectively. \n",
    "dataSet_partial[\"Clue_Length_Words\"] = dataSet_partial['Clue'].apply(lambda x: len(x.split()))\n",
    "dataSet_partial['Word_Length_Chars'] = dataSet_partial['Word'].apply(len)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(dataSet_partial['Clue_Length_Words'], bins=20, color='green')\n",
    "plt.title('Hist of Clue Length (Words)')\n",
    "plt.xlable('Num of Words')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(dataSet_partial['Word_Length_Chars'], bins=20, color='skyblue')\n",
    "plt.title('Hist of Answer Length (char)')\n",
    "plt.xlabel(\"Num of Chars\")\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.titght_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0e3a07",
   "metadata": {},
   "source": [
    "This code illustrates a scatter plot where the x-axis represents the lengths of clue in terms of words and the y-axis represents the lengths of words in terms of characters. Each point in the scatter plot corresponds to a clue/answer pair from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e471670",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = dataSet.dropna(subset=['Word_Length_Chars'])\n",
    "\n",
    "plt.figure(figsize=(14.5,6))\n",
    "plt.scatter(dataSet['Clue_Length_Words'], dataSet['Word_Length_Chars'], color='purple', alpha=0.2)\n",
    "plt.title('Clue Length v. Word Length')\n",
    "plt.xlabel('Clue Length (Words)')\n",
    "plt.ylabel('Word Length (Chars)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249d9be1",
   "metadata": {},
   "source": [
    "The code below is designed to help make predictions based on clues and certain characteristics of words. \n",
    "\n",
    "It loads a partial amount of the dataset (3000 rows) and determines the length of each word (crossword answer). \n",
    "\n",
    "TF-IDF (Term Frequency - Inverse Document Frequency):\n",
    "\n",
    "TF computes how often each word appears in each clue. It gives higher weights to words that occur more frequently within a clue. \n",
    "\n",
    "IDF calculates the importance of each word in the entire set of clues. It assigns higher weights to wrods that are uncommon across all clues but occur often in a specific clue. So, words that are common across many clues are given lower IDF values.\n",
    "\n",
    "For each word in each clue, TF-IDF computes a numberical value that represents the importance of that word in that particular clue relative to its importance to all clues. \n",
    "\n",
    "# Warning: this code took 14 min to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72be50e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = dataSet_partial['Clue']\n",
    "y = dataSet_partial['Word']\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_encoded = tfidf_vectorizer.fit_transform(X).toarray()\n",
    "\n",
    "# Calculate character size based on the length of words\n",
    "character_size = dataSet_partial['Word'].apply(len)\n",
    "\n",
    "# Concatenate encoded clues and character size into a DataFrame\n",
    "X_processed = pd.DataFrame(X_encoded, columns=tfidf_vectorizer.get_feature_names_out())\n",
    "X_processed['Character_Size'] = character_size.values\n",
    "\n",
    "# this code trains a logistical regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_processed, y)\n",
    "\n",
    "# User Input\n",
    "user_input_clue = input(\"Enter the clue: \")\n",
    "user_input_size = int(input(\"Enter the character size of the answer: \"))\n",
    "\n",
    "# Preprocess user input similarly to the training data (tfidf encoding)\n",
    "user_input_encoded = tfidf_vectorizer.transform([user_input_clue]).toarray()\n",
    "\n",
    "# This creates a dataframe so the model can make a prediction\n",
    "user_input_df = pd.DataFrame(user_input_encoded, columns=tfidf_vectorizer.get_feature_names_out())\n",
    "user_input_df['Character_Size'] = user_input_size\n",
    "\n",
    "# This code makes the prediction\n",
    "predicted_word = model.predict(user_input_df)\n",
    "\n",
    "print(f\"Predicted word based on the clue '{user_input_clue}' and character size {user_input_size}: {predicted_word[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8e9151",
   "metadata": {},
   "source": [
    "Fantastic! This model accurately predicted the answer for the clue that I provided. Granted, it was a test run and the clue was already present in the dataset that I fed into the model. Next time, I will input a clue that's not within the partial dataset that I loaded."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
